{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üöÄ Diffusion Language Model - Complete Training & Demo\n",
        "\n",
        "This notebook provides:\n",
        "1. PDF data processing pipeline\n",
        "2. Model initialization with Flash Attention\n",
        "3. Interactive training with progress visualization\n",
        "4. Generation and evaluation\n",
        "\n",
        "**Note**: Flash Attention is enabled by default for faster training!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üì¶ 1. Setup & Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install Flash Attention (if not installed)\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    import flash_attn\n",
        "    print(\"‚úÖ Flash Attention already installed\")\n",
        "except ImportError:\n",
        "    print(\"Installing Flash Attention...\")\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"flash-attn\", \"--no-build-isolation\"])\n",
        "    print(\"‚úÖ Flash Attention installed\")\n",
        "\n",
        "# Import all dependencies\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import json\n",
        "from pathlib import Path\n",
        "from transformers import AutoTokenizer\n",
        "from typing import List, Dict, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Add parent directory to path for imports\n",
        "sys.path.append(os.path.dirname(os.getcwd()))\n",
        "\n",
        "from model.diffusion import DiffusionLM, DiffusionSchedule\n",
        "from model.transformer import FLASH_AVAILABLE\n",
        "from data.pdf_processor import PDFProcessor\n",
        "from data.dataset import create_dataloader, DiffusionDataset\n",
        "from training.config import TrainingConfig\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üñ•Ô∏è Using device: {device}\")\n",
        "print(f\"‚ö° Flash Attention available: {FLASH_AVAILABLE}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéÆ GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìÑ 2. Data Processing Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize PDF processor\n",
        "pdf_processor = PDFProcessor(\n",
        "    min_length=100,\n",
        "    max_length=512,\n",
        "    clean_text=True,\n",
        "    use_pdfplumber=True  # Better extraction quality\n",
        ")\n",
        "\n",
        "# Configuration\n",
        "PDF_FOLDER = \"pdfs\"  # Update this path to your PDF folder\n",
        "DATA_OUTPUT = \"data/processed\"\n",
        "CREATE_SAMPLE_DATA = True  # Set to False if you have PDFs\n",
        "\n",
        "print(\"üìö PDF Processor initialized\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process PDFs or create sample data\n",
        "if CREATE_SAMPLE_DATA:\n",
        "    # Create sample training data for demo\n",
        "    sample_texts = [\n",
        "        \"The diffusion language model learns to generate text by progressively denoising masked tokens through iterative refinement.\",\n",
        "        \"Machine learning models can be trained using various optimization techniques including gradient descent and adaptive learning rates.\",\n",
        "        \"Natural language processing has made significant advances with transformer architectures and attention mechanisms.\",\n",
        "        \"Deep learning requires large amounts of data and computational resources for training complex neural networks.\",\n",
        "        \"The attention mechanism allows models to focus on relevant parts of the input sequence for better understanding.\",\n",
        "        \"Neural networks consist of interconnected layers that process information hierarchically through forward propagation.\",\n",
        "        \"Text generation models can produce coherent and contextually relevant outputs using language modeling objectives.\",\n",
        "        \"Pretrained language models can be fine-tuned for specific downstream tasks with transfer learning.\",\n",
        "        \"The transformer architecture has revolutionized natural language understanding with self-attention mechanisms.\",\n",
        "        \"Diffusion models iteratively refine noisy inputs to generate high-quality outputs through reverse diffusion.\",\n",
        "        \"Gradient-based optimization methods help neural networks learn optimal parameters from training data.\",\n",
        "        \"Recurrent neural networks process sequential data by maintaining hidden states across time steps.\",\n",
        "        \"Convolutional neural networks excel at processing grid-like data such as images and spectrograms.\",\n",
        "        \"Reinforcement learning agents learn optimal policies through interaction with environments and rewards.\",\n",
        "        \"Generative adversarial networks consist of generator and discriminator networks in competition.\",\n",
        "        \"Variational autoencoders learn latent representations through probabilistic encoding and decoding.\",\n",
        "        \"Meta-learning algorithms enable models to quickly adapt to new tasks with limited examples.\",\n",
        "        \"Contrastive learning methods learn representations by comparing positive and negative sample pairs.\",\n",
        "        \"Knowledge distillation transfers knowledge from large teacher models to smaller student models.\",\n",
        "        \"Multi-task learning shares representations across related tasks for improved generalization.\"\n",
        "    ] * 5  # Repeat for more data\n",
        "    \n",
        "    # Save as training data\n",
        "    os.makedirs('data', exist_ok=True)\n",
        "    with open('data/train_data.json', 'w') as f:\n",
        "        json.dump({'texts': sample_texts}, f, indent=2)\n",
        "    \n",
        "    print(f\"‚úÖ Created sample dataset with {len(sample_texts)} text samples\")\n",
        "    data_path = 'data/train_data.json'\n",
        "    \n",
        "else:\n",
        "    # Process actual PDFs\n",
        "    if os.path.exists(PDF_FOLDER):\n",
        "        print(f\"üìÇ Processing PDFs from {PDF_FOLDER}\")\n",
        "        docs = pdf_processor.process_folder(\n",
        "            PDF_FOLDER, \n",
        "            output_dir=DATA_OUTPUT,\n",
        "            save_format='json'\n",
        "        )\n",
        "        print(f\"‚úÖ Processed {len(docs)} documents\")\n",
        "        data_path = f\"{DATA_OUTPUT}/all_documents.json\"\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è PDF folder '{PDF_FOLDER}' not found. Creating sample data instead...\")\n",
        "        CREATE_SAMPLE_DATA = True\n",
        "\n",
        "print(f\"üìç Data path: {data_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ü§ñ 3. Model Initialization with Flash Attention\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training configuration\n",
        "config = TrainingConfig(\n",
        "    data_path=data_path,\n",
        "    batch_size=4 if device.type == 'cuda' else 2,  # Smaller batch for CPU\n",
        "    learning_rate=5e-4,\n",
        "    num_epochs=10,  # Adjust based on your needs\n",
        "    max_length=128,  # Sequence length\n",
        "    num_timesteps=50,  # Diffusion steps\n",
        "    device=str(device),\n",
        "    \n",
        "    # Model configuration\n",
        "    vocab_size=30000,\n",
        "    d_model=256,  # Model dimension\n",
        "    n_heads=8,\n",
        "    n_layers=4,  # Number of transformer layers\n",
        "    d_ff=1024,\n",
        "    dropout=0.1,\n",
        "    \n",
        "    # Logging\n",
        "    log_interval=10,\n",
        "    eval_interval=50,\n",
        "    save_interval=100,\n",
        "    \n",
        "    # Generation\n",
        "    num_generation_steps=30,\n",
        "    generation_temperature=1.0,\n",
        "    generation_top_p=0.95\n",
        ")\n",
        "\n",
        "print(\"‚öôÔ∏è Configuration set\")\n",
        "print(f\"  - Batch size: {config.batch_size}\")\n",
        "print(f\"  - Learning rate: {config.learning_rate}\")\n",
        "print(f\"  - Model dimension: {config.d_model}\")\n",
        "print(f\"  - Layers: {config.n_layers}\")\n",
        "print(f\"  - Flash Attention: Enabled by default\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
        "if tokenizer.mask_token is None:\n",
        "    tokenizer.add_special_tokens({'mask_token': '[MASK]'})\n",
        "\n",
        "# Update vocab size\n",
        "config.vocab_size = len(tokenizer)\n",
        "\n",
        "# Initialize model with Flash Attention\n",
        "model = DiffusionLM(\n",
        "    vocab_size=config.vocab_size,\n",
        "    d_model=config.d_model,\n",
        "    n_heads=config.n_heads,\n",
        "    n_layers=config.n_layers,\n",
        "    d_ff=config.d_ff,\n",
        "    max_seq_len=config.max_length,\n",
        "    num_timesteps=config.num_timesteps,\n",
        "    dropout=config.dropout,\n",
        "    mask_token_id=tokenizer.mask_token_id,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    use_flash=True  # Enable Flash Attention\n",
        ").to(device)\n",
        "\n",
        "# Model statistics\n",
        "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nüß† Model initialized:\")\n",
        "print(f\"  - Parameters: {num_params:,}\")\n",
        "print(f\"  - Vocabulary size: {config.vocab_size:,}\")\n",
        "print(f\"  - Mask token: {tokenizer.mask_token}\")\n",
        "print(f\"  - Memory usage: {num_params * 4 / 1e6:.2f} MB (FP32)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìä 4. Data Loading & Preparation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataloaders\n",
        "print(\"üìä Loading datasets...\")\n",
        "\n",
        "train_dataloader = create_dataloader(\n",
        "    config.data_path,\n",
        "    batch_size=config.batch_size,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=config.max_length,\n",
        "    shuffle=True,\n",
        "    num_workers=0  # Set to 0 for Windows compatibility\n",
        ")\n",
        "\n",
        "# Create validation split (using same data for demo)\n",
        "val_dataloader = create_dataloader(\n",
        "    config.data_path,\n",
        "    batch_size=config.batch_size,\n",
        "    tokenizer=tokenizer,\n",
        "    max_length=config.max_length,\n",
        "    shuffle=False,\n",
        "    num_workers=0\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ Data loaded:\")\n",
        "print(f\"  - Training batches: {len(train_dataloader)}\")\n",
        "print(f\"  - Validation batches: {len(val_dataloader)}\")\n",
        "print(f\"  - Batch size: {config.batch_size}\")\n",
        "print(f\"  - Max sequence length: {config.max_length}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üèãÔ∏è 5. Interactive Training with Live Progress\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup training\n",
        "from model.utils import get_linear_schedule_with_warmup\n",
        "\n",
        "# Initialize optimizer\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config.learning_rate,\n",
        "    weight_decay=config.weight_decay\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "num_training_steps = len(train_dataloader) * config.num_epochs\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps=min(100, num_training_steps // 10),\n",
        "    num_training_steps=num_training_steps\n",
        ")\n",
        "\n",
        "# Training metrics storage\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "print(f\"üéØ Training setup complete:\")\n",
        "print(f\"  - Optimizer: AdamW\")\n",
        "print(f\"  - Learning rate: {config.learning_rate}\")\n",
        "print(f\"  - Total training steps: {num_training_steps}\")\n",
        "print(f\"  - Warmup steps: {min(100, num_training_steps // 10)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Interactive training loop with live visualization\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def train_epoch(model, dataloader, optimizer, scheduler, epoch, config):\n",
        "    \"\"\"Train for one epoch with progress tracking.\"\"\"\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    epoch_acc = 0\n",
        "    num_batches = 0\n",
        "    \n",
        "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{config.num_epochs}\")\n",
        "    \n",
        "    for batch_idx, batch in enumerate(progress_bar):\n",
        "        # Move to device\n",
        "        input_ids = batch['input_ids'].to(config.device)\n",
        "        \n",
        "        # Forward pass\n",
        "        outputs = model(input_ids)\n",
        "        \n",
        "        # Compute loss\n",
        "        loss = model.compute_loss(\n",
        "            outputs['logits'],\n",
        "            input_ids,\n",
        "            outputs['mask']\n",
        "        )\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), config.gradient_clip)\n",
        "        \n",
        "        # Optimizer step\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # Calculate accuracy\n",
        "        with torch.no_grad():\n",
        "            mask = outputs['mask']\n",
        "            if mask.any():\n",
        "                preds = outputs['logits'][mask].argmax(dim=-1)\n",
        "                targets = input_ids[mask]\n",
        "                accuracy = (preds == targets).float().mean().item()\n",
        "            else:\n",
        "                accuracy = 0.0\n",
        "        \n",
        "        # Update metrics\n",
        "        epoch_loss += loss.item()\n",
        "        epoch_acc += accuracy\n",
        "        num_batches += 1\n",
        "        \n",
        "        # Update progress bar\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f'{loss.item():.4f}',\n",
        "            'acc': f'{accuracy:.3f}',\n",
        "            'lr': f'{scheduler.get_last_lr()[0]:.6f}'\n",
        "        })\n",
        "        \n",
        "        # Store metrics for plotting\n",
        "        if batch_idx % 5 == 0:\n",
        "            train_losses.append(loss.item())\n",
        "            train_accuracies.append(accuracy)\n",
        "    \n",
        "    return epoch_loss / num_batches, epoch_acc / num_batches\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, config):\n",
        "    \"\"\"Evaluate model on validation set.\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "    num_batches = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
        "            input_ids = batch['input_ids'].to(config.device)\n",
        "            \n",
        "            # Forward pass\n",
        "            outputs = model(input_ids)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = model.compute_loss(\n",
        "                outputs['logits'],\n",
        "                input_ids,\n",
        "                outputs['mask']\n",
        "            )\n",
        "            \n",
        "            # Calculate accuracy\n",
        "            mask = outputs['mask']\n",
        "            if mask.any():\n",
        "                preds = outputs['logits'][mask].argmax(dim=-1)\n",
        "                targets = input_ids[mask]\n",
        "                accuracy = (preds == targets).float().mean().item()\n",
        "            else:\n",
        "                accuracy = 0.0\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            total_acc += accuracy\n",
        "            num_batches += 1\n",
        "    \n",
        "    return total_loss / num_batches, total_acc / num_batches\n",
        "\n",
        "\n",
        "print(\"‚úÖ Training functions defined\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start training with live progress visualization\n",
        "print(\"üöÄ Starting training with Flash Attention...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Setup for live plotting\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "fig.suptitle('Training Progress', fontsize=14)\n",
        "\n",
        "best_val_loss = float('inf')\n",
        "os.makedirs('checkpoints', exist_ok=True)\n",
        "\n",
        "for epoch in range(config.num_epochs):\n",
        "    # Train for one epoch\n",
        "    train_loss, train_acc = train_epoch(\n",
        "        model, train_dataloader, optimizer, scheduler, epoch, config\n",
        "    )\n",
        "    \n",
        "    # Evaluate\n",
        "    val_loss, val_acc = evaluate(model, val_dataloader, config)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accuracies.append(val_acc)\n",
        "    \n",
        "    # Print epoch summary\n",
        "    print(f\"\\nüìà Epoch {epoch+1}/{config.num_epochs}\")\n",
        "    print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.3f}\")\n",
        "    print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.3f}\")\n",
        "    \n",
        "    # Save best model\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'config': config.to_dict(),\n",
        "            'val_loss': val_loss\n",
        "        }, 'checkpoints/best_model.pt')\n",
        "        print(f\"  üíæ Saved best model (val_loss: {val_loss:.4f})\")\n",
        "    \n",
        "    # Update live plot\n",
        "    clear_output(wait=True)\n",
        "    \n",
        "    # Plot losses\n",
        "    axes[0].clear()\n",
        "    if len(train_losses) > 0:\n",
        "        axes[0].plot(train_losses, label='Train', alpha=0.7)\n",
        "    if len(val_losses) > 0:\n",
        "        axes[0].plot(np.arange(0, len(val_losses)) * len(train_dataloader), \n",
        "                    val_losses, label='Val', marker='o')\n",
        "    axes[0].set_xlabel('Steps')\n",
        "    axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Loss over Time')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot accuracies\n",
        "    axes[1].clear()\n",
        "    if len(train_accuracies) > 0:\n",
        "        axes[1].plot(train_accuracies, label='Train', alpha=0.7)\n",
        "    if len(val_accuracies) > 0:\n",
        "        axes[1].plot(np.arange(0, len(val_accuracies)) * len(train_dataloader), \n",
        "                    val_accuracies, label='Val', marker='o')\n",
        "    axes[1].set_xlabel('Steps')\n",
        "    axes[1].set_ylabel('Accuracy')\n",
        "    axes[1].set_title('Accuracy over Time')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    # Generate sample every 2 epochs\n",
        "    if (epoch + 1) % 2 == 0:\n",
        "        print(\"\\nüé® Generating sample...\")\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            generated = model.generate(\n",
        "                prompt=None,\n",
        "                max_length=50,\n",
        "                num_steps=config.num_generation_steps,\n",
        "                temperature=config.generation_temperature,\n",
        "                top_p=config.generation_top_p\n",
        "            )\n",
        "            generated_text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "            print(f\"  Generated: {generated_text[:150]}...\")\n",
        "        model.train()\n",
        "\n",
        "print(\"\\n‚úÖ Training complete!\")\n",
        "print(f\"Best validation loss: {best_val_loss:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üé® 6. Text Generation & Evaluation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load best model for generation\n",
        "checkpoint = torch.load('checkpoints/best_model.pt', map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(f\"‚úÖ Loaded best model from epoch {checkpoint['epoch']+1}\")\n",
        "print(f\"  Validation loss: {checkpoint['val_loss']:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate text samples\n",
        "print(\"üé® Generating text samples...\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "num_samples = 5\n",
        "generated_texts = []\n",
        "\n",
        "for i in range(num_samples):\n",
        "    with torch.no_grad():\n",
        "        # Generate from scratch\n",
        "        generated = model.generate(\n",
        "            prompt=None,\n",
        "            max_length=60,\n",
        "            num_steps=30,\n",
        "            temperature=0.9,\n",
        "            top_p=0.95\n",
        "        )\n",
        "        \n",
        "        generated_text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "        generated_texts.append(generated_text)\n",
        "        \n",
        "        print(f\"\\nüìù Sample {i+1}:\")\n",
        "        print(f\"  {generated_text}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üîÆ 7. Text Infilling / Completion\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text infilling demonstration\n",
        "print(\"üîÆ Text Infilling Demo\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "templates = [\n",
        "    \"The [MASK] [MASK] model can [MASK] text efficiently.\",\n",
        "    \"Machine learning [MASK] are trained using [MASK] [MASK].\",\n",
        "    \"[MASK] attention mechanisms allow [MASK] to focus on [MASK] parts.\",\n",
        "    \"The transformer [MASK] has revolutionized [MASK] [MASK] processing.\",\n",
        "]\n",
        "\n",
        "for template in templates:\n",
        "    print(f\"\\nüìù Template: {template}\")\n",
        "    \n",
        "    # Tokenize template\n",
        "    inputs = tokenizer(\n",
        "        template,\n",
        "        return_tensors='pt',\n",
        "        padding='max_length',\n",
        "        max_length=30,\n",
        "        truncation=True\n",
        "    )\n",
        "    input_ids = inputs['input_ids'].to(device)\n",
        "    \n",
        "    # Fill in the masks\n",
        "    with torch.no_grad():\n",
        "        filled = model.reverse_diffusion(\n",
        "            input_ids,\n",
        "            num_steps=20,\n",
        "            temperature=0.8,\n",
        "            confidence_threshold=0.7\n",
        "        )\n",
        "    \n",
        "    filled_text = tokenizer.decode(filled[0], skip_special_tokens=True)\n",
        "    print(f\"‚ú® Filled:   {filled_text}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üìà 8. Visualizations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize diffusion process\n",
        "print(\"üìä Visualizing Diffusion Process\")\n",
        "\n",
        "# Sample text for visualization\n",
        "sample_text = \"The diffusion model learns to generate text.\"\n",
        "inputs = tokenizer(sample_text, return_tensors='pt', padding='max_length', \n",
        "                   max_length=20, truncation=True)\n",
        "input_ids = inputs['input_ids'].to(device)\n",
        "\n",
        "# Track diffusion process\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "fig.suptitle('Forward Diffusion Process (Masking)', fontsize=14)\n",
        "\n",
        "timesteps = [0, 10, 20, 30, 40, 49]\n",
        "masks_history = []\n",
        "\n",
        "for idx, t in enumerate(timesteps):\n",
        "    ax = axes[idx // 3, idx % 3]\n",
        "    \n",
        "    # Apply forward diffusion\n",
        "    t_tensor = torch.tensor([t], device=device)\n",
        "    with torch.no_grad():\n",
        "        noised_ids, mask = model.forward_diffusion(input_ids, t_tensor)\n",
        "    \n",
        "    masks_history.append(mask[0].cpu().numpy())\n",
        "    \n",
        "    # Visualize mask\n",
        "    mask_visual = mask[0].cpu().numpy()[:20].reshape(1, -1)\n",
        "    im = ax.imshow(mask_visual, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)\n",
        "    \n",
        "    # Decode text\n",
        "    text = tokenizer.decode(noised_ids[0][:20], skip_special_tokens=False)\n",
        "    \n",
        "    ax.set_title(f't={t} ({mask.float().mean():.1%} masked)')\n",
        "    ax.set_xlabel('Token Position')\n",
        "    ax.set_yticks([])\n",
        "    ax.set_xticks(range(0, 20, 5))\n",
        "    \n",
        "    # Add text below\n",
        "    wrapped_text = text[:40] + \"...\" if len(text) > 40 else text\n",
        "    ax.text(0.5, -0.15, wrapped_text, transform=ax.transAxes, \n",
        "            ha='center', fontsize=8, wrap=True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.colorbar(im, ax=axes, label='Masked (1) vs Unmasked (0)', \n",
        "             orientation='horizontal', fraction=0.05, pad=0.15)\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Diffusion visualization complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üíæ 9. Save & Export\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save final model and training history\n",
        "print(\"üíæ Saving model and results...\")\n",
        "\n",
        "# Save model with full configuration\n",
        "model_save_path = 'checkpoints/final_model.pt'\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'config': config.to_dict(),\n",
        "    'vocab_size': len(tokenizer),\n",
        "    'training_history': {\n",
        "        'train_losses': train_losses[-100:],  # Save last 100 steps\n",
        "        'val_losses': val_losses,\n",
        "        'val_accuracies': val_accuracies\n",
        "    }\n",
        "}, model_save_path)\n",
        "\n",
        "print(f\"‚úÖ Model saved to {model_save_path}\")\n",
        "\n",
        "# Export configuration\n",
        "config_path = 'checkpoints/config.json'\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(config.to_dict(), f, indent=2)\n",
        "print(f\"‚úÖ Configuration saved to {config_path}\")\n",
        "\n",
        "# Save generated samples\n",
        "samples_path = 'checkpoints/generated_samples.txt'\n",
        "with open(samples_path, 'w', encoding='utf-8') as f:\n",
        "    for i, text in enumerate(generated_texts):\n",
        "        f.write(f\"Sample {i+1}:\\n{text}\\n\\n\")\n",
        "print(f\"‚úÖ Generated samples saved to {samples_path}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"üéâ All done! Your model is trained and ready to use.\")\n",
        "print(\"\\nTo load the model later:\")\n",
        "print(\"```python\")\n",
        "print(\"checkpoint = torch.load('checkpoints/final_model.pt')\")\n",
        "print(\"model.load_state_dict(checkpoint['model_state_dict'])\")\n",
        "print(\"```\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## üéØ Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "1. ‚úÖ **PDF Processing**: Extract and prepare text data from PDFs\n",
        "2. ‚úÖ **Flash Attention**: Enabled by default for 2-3x faster training\n",
        "3. ‚úÖ **Interactive Training**: Live progress visualization with plots\n",
        "4. ‚úÖ **Text Generation**: Generate coherent text from scratch\n",
        "5. ‚úÖ **Text Infilling**: Fill in masked tokens intelligently\n",
        "6. ‚úÖ **Visualization**: See the diffusion process in action\n",
        "\n",
        "### Next Steps:\n",
        "- üìö Add more training data (PDFs)\n",
        "- üîß Tune hyperparameters in config\n",
        "- üöÄ Scale up model size for better quality\n",
        "- üé® Experiment with different generation settings\n",
        "- üí° Try conditional generation with prompts\n",
        "\n",
        "**Flash Attention Note**: If you have a compatible GPU (Ampere or newer), Flash Attention provides significant speedup. The model automatically falls back to standard attention if Flash Attention is not available.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "default",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
